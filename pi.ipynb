{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from piplyr import piplyr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: piplyr 1.0\n",
      "Uninstalling piplyr-1.0:\n",
      "  Would remove:\n",
      "    /Users/shh/anaconda3/lib/python3.11/site-packages/piplyr-1.0.dist-info/*\n",
      "    /Users/shh/anaconda3/lib/python3.11/site-packages/piplyr/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## DocStrings\n",
    "\n",
    "class piplyr:\n",
    "    \"\"\"\n",
    "    A class providing dplyr-like data manipulation capabilities for pandas DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initializes the piplyr class with a pandas DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): A pandas DataFrame to be manipulated.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "            >>> pi = piplyr(df)\n",
    "        \"\"\"\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "        self.df = df.copy()\n",
    "        self.grouped = None\n",
    "\n",
    "    def group_by(self, *group_vars):\n",
    "        \"\"\"\n",
    "        Groups the DataFrame by specified columns.\n",
    "\n",
    "        Args:\n",
    "            group_vars: Columns to group by. Multiple columns can be specified.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame grouped.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 1], 'B': [5, 6, 7]})\n",
    "            >>> pi = piplyr(df).group_by('A')\n",
    "        \"\"\"\n",
    "        if not all(col in self.df.columns for col in group_vars):\n",
    "            raise ValueError(\"One or more grouping columns not found in DataFrame\")\n",
    "        self.grouped = self.df.groupby(list(group_vars))\n",
    "        return self\n",
    "\n",
    "    def sort_by(self, column, ascending=True):\n",
    "        \"\"\"\n",
    "        Sorts the DataFrame by a specified column.\n",
    "\n",
    "        Args:\n",
    "            column: The column to sort by.\n",
    "            ascending: Whether to sort in ascending order (default is True).\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame sorted.\n",
    "             Examples:\n",
    "            >>> df = pd.DataFrame({'A': [3, 1, 2]})\n",
    "            >>> pi = piplyr(df).sort_by('A')\n",
    "        \"\"\"\n",
    "        if column not in self.df.columns:\n",
    "            raise ValueError(f\"Column {column} not found in DataFrame\")\n",
    "        self.df = self.df.sort_values(by=column, ascending=ascending)\n",
    "        return self\n",
    "\n",
    "    def select(self, *columns):\n",
    "        \"\"\"\n",
    "        Selects specified columns from the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            columns: A list of column names to keep in the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with only the selected columns.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "            >>> pi = piplyr(df).select('A', 'B')\n",
    "        \"\"\"\n",
    "        missing_cols = [col for col in columns if col not in self.df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Columns {missing_cols} not found in DataFrame\")\n",
    "        self.df = self.df[list(columns)]\n",
    "        return self\n",
    "\n",
    "    def drop_col(self, *columns):\n",
    "        \"\"\"\n",
    "        Drops specified columns from the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            columns: A list of column names to drop from the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with specified columns removed.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "            >>> pi = piplyr(df).drop_col('C')\n",
    "        \"\"\"\n",
    "        missing_cols = [col for col in columns if col not in self.df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Columns {missing_cols} not found in DataFrame\")\n",
    "        self.df = self.df.drop(columns=list(columns))\n",
    "        return self\n",
    "\n",
    "    def rename_col(self, rename_dict):\n",
    "        \"\"\"\n",
    "        Renames columns in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            rename_dict: A dictionary mapping old column names to new column names.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with columns renamed.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3]})\n",
    "            >>> pi = piplyr(df).rename_col({'A': 'new_A'})\n",
    "        \"\"\"\n",
    "        self.df = self.df.rename(columns=rename_dict)\n",
    "        return self\n",
    "\n",
    "    def filter_row(self, condition):\n",
    "        \"\"\"\n",
    "        Filters rows based on a given condition.\n",
    "\n",
    "        Args:\n",
    "            condition: A string of condition to filter the DataFrame rows. \n",
    "                       The condition should be in a format that can be used inside DataFrame.query().\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with rows filtered based on the condition.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "            >>> pi = piplyr(df).filter_row('A > 1')\n",
    "        \"\"\"\n",
    "        self.df = self.df.query(condition)\n",
    "        return self\n",
    "\n",
    "    def mutate(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Adds new columns or modifies existing ones based on given expressions.\n",
    "        When used after 'group_by', applies the mutation within each group.\n",
    "\n",
    "        Args:\n",
    "            kwargs: Key-value pairs where keys are new or existing column names \n",
    "                    and values are expressions or functions to compute their values.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with new or modified columns.\n",
    "\n",
    "        Examples:\n",
    "            Without grouping:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "            >>> pi = piplyr(df).mutate(new_col=lambda x: x['A'] * 2)\n",
    "\n",
    "            With grouping:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': ['X', 'Y', 'X']})\n",
    "            >>> pi = piplyr(df).group_by('C').mutate(mean_val=lambda x: np.mean(x['A']))\n",
    "        \"\"\"\n",
    "        if self.grouped:\n",
    "            for new_col, func in kwargs.items():\n",
    "                if callable(func):\n",
    "                    # Apply the function to each group and assign the result\n",
    "                    self.df[new_col] = self.grouped.apply(lambda x: func(x)).reset_index(level=0, drop=True)\n",
    "                else:\n",
    "                    raise ValueError(\"With grouping, provide a callable function for mutation.\")\n",
    "        else:\n",
    "            for new_col, expression in kwargs.items():\n",
    "                if callable(expression):\n",
    "                    self.df[new_col] = expression(self.df)\n",
    "                else:\n",
    "                    raise ValueError(\"Mutation expressions must be callable.\")\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def summarize(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Performs summary/aggregation operations on the DataFrame.\n",
    "        If used after 'group_by', provides aggregated statistics for each group.\n",
    "        Without 'group_by', provides aggregated statistics for the entire DataFrame.\n",
    "\n",
    "        Args:\n",
    "            kwargs: Key-value pairs where keys are new column names for the aggregated values and\n",
    "                    values are aggregation functions.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with a DataFrame containing summary statistics.\n",
    "\n",
    "        Examples:\n",
    "            Without grouping:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "            >>> pi = piplyr(df).summarize(mean_A=np.mean('A'), sum_B=np.sum('B'))\n",
    "\n",
    "            With grouping:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': ['X', 'Y', 'X']})\n",
    "            >>> pi = piplyr(df).group_by('C').summarize(mean_val=lambda x: np.mean(x['A']))\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        if self.grouped:\n",
    "            def agg_func(group):\n",
    "                result = {}\n",
    "                for new_col, func in kwargs.items():\n",
    "                    if callable(func):\n",
    "                        result[new_col] = func(group)\n",
    "                    else:\n",
    "                        raise ValueError(\"Aggregation function must be callable\")\n",
    "                return pd.Series(result)\n",
    "\n",
    "            self.df = self.grouped.apply(agg_func).reset_index()\n",
    "        else:\n",
    "            result = {}\n",
    "            for new_col, func in kwargs.items():\n",
    "                if callable(func):\n",
    "                    result[new_col] = func(self.df)\n",
    "                else:\n",
    "                    raise ValueError(\"Aggregation function must be callable\")\n",
    "            self.df = pd.DataFrame(result, index=[0])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def agg_funcs(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply multiple aggregation functions to columns.\n",
    "\n",
    "        Args:\n",
    "            kwargs: Key-value pairs where the key is the column name and the value is a list of aggregation functions.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object with aggregated DataFrame.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "            >>> pi = piplyr(df).agg_funcs(A=['sum', 'mean'], B=['min', 'max'])\n",
    "        \"\"\"\n",
    "        agg_dict = {col: funcs for col, funcs in kwargs.items()}\n",
    "        self.df = self.df.agg(agg_dict)\n",
    "        return self\n",
    "    \n",
    "    def rowwise(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply a function row-wise to the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            func: A function to apply to each row.\n",
    "            *args, **kwargs: Additional arguments and keyword arguments for the function.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "            >>> func = lambda row: row['A'] + row['B']\n",
    "            >>> pi = piplyr(df).rowwise(func)\n",
    "        \"\"\"\n",
    "        self.df = self.df.apply(lambda row: func(row, *args, **kwargs), axis=1)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def sample_n(self, n):\n",
    "        \"\"\"\n",
    "        Randomly sample n rows from the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            n: Number of rows to sample.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': range(10), 'B': range(10, 20)})\n",
    "            >>> pi = piplyr(df).sample_n(5)\n",
    "        \"\"\"\n",
    "        self.df = self.df.sample(n=n)\n",
    "        return self\n",
    "    \n",
    "    def sample_frac(self, frac):\n",
    "        \"\"\"\n",
    "        Randomly sample a fraction of rows from the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            frac: Fraction of rows to sample.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': range(10), 'B': range(10, 20)})\n",
    "            >>> pi = piplyr(df).sample_frac(0.5)\n",
    "        \"\"\"\n",
    "        self.df = self.df.sample(frac=frac)\n",
    "        return self\n",
    "    \n",
    "    def mutate_conditional(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply conditional mutations to columns.\n",
    "\n",
    "        Args:\n",
    "            kwargs: Key-value pairs where keys are column names and values are tuples of (condition, value).\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': [10, 20], 'B': [30, 40]})\n",
    "            >>> pi = piplyr(df).mutate_conditional(A=('A > 15', 100), B=('B < 35', 200))\n",
    "        \"\"\"\n",
    "        for col, (condition, value) in kwargs.items():\n",
    "            self.df.loc[self.df.eval(condition), col] = value\n",
    "        return self\n",
    "        \n",
    "    def bin_data(self, column, bins):\n",
    "        \"\"\"\n",
    "        Bin numeric data into categories.\n",
    "\n",
    "        Args:\n",
    "            column: The column to bin.\n",
    "            bins: The edges defining the bins.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 4, 6, 8]})\n",
    "            >>> pi = piplyr(df).bin_data('A', bins=[0, 3, 6, 9])\n",
    "        \"\"\"\n",
    "        self.df[column + '_binned'] = pd.cut(self.df[column], bins=bins)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def groupwise_custom(self, group_vars, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Apply a custom function to groups within the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            group_vars: Columns to group by.\n",
    "            func: Custom function to apply to each group.\n",
    "            *args, **kwargs: Additional arguments and keyword arguments for the function.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Group': ['A', 'A', 'B', 'B'], 'Value': [1, 2, 3, 4]})\n",
    "            >>> func = lambda x: x.sum()\n",
    "            >>> pi = piplyr(df).groupwise_custom('Group', func)\n",
    "        \"\"\"\n",
    "        self.grouped = self.df.groupby(group_vars)\n",
    "        self.df = self.grouped.apply(lambda x: func(x, *args, **kwargs)).reset_index(drop=True)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def groupwise_np(self, group_by, target_col, func):\n",
    "        \"\"\"\n",
    "        Apply a custom function to a specific column within groups of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            group_by: The column name to group by.\n",
    "            target_col: The target column to apply the function.\n",
    "            func: The function to apply.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'F': ['x', 'x', 'y', 'y'], 'A': [1, 2, 3, 4]})\n",
    "            >>> pi = piplyr(df).groupwise_np('F', 'A', np.mean)\n",
    "        \"\"\"\n",
    "        self.df = self.df.groupby(group_by)[target_col].apply(func).reset_index()\n",
    "        return self\n",
    "    \n",
    "    def sql_plyr(self, expression):\n",
    "        \"\"\"\n",
    "        Executes an SQL query on the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            expression: The SQL query to execute.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified by the SQL query.\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(':memory:') as con:\n",
    "            self.df.to_sql('df', con, index=False)\n",
    "            self.df = pd.read_sql_query(expression, con)\n",
    "        return self\n",
    "\n",
    "    def convert_dtype(self, column, dtype):\n",
    "        \"\"\"\n",
    "        Convert the data type of a specified column.\n",
    "\n",
    "        Args:\n",
    "            column: The column whose data type is to be converted.\n",
    "            dtype: The target data type.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['1', '2', '3']})\n",
    "            >>> pi = piplyr(df).convert_dtype('A', int)\n",
    "        \"\"\"\n",
    "        self.df[column] = self.df[column].astype(dtype)\n",
    "        return self\n",
    "\n",
    "    def pipe(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Allows the use of external functions in a chain.\n",
    "\n",
    "        Args:\n",
    "            func: A function to apply to the DataFrame.\n",
    "            *args, **kwargs: Additional arguments and keyword arguments for the function.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        \"\"\"\n",
    "        self.df = func(self.df, *args, **kwargs)\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def case_when(self, cases, target_var):\n",
    "        \"\"\"\n",
    "        Applies conditions and assigns values based on them, similar to SQL's CASE WHEN.\n",
    "\n",
    "        Args:\n",
    "            cases: A list of tuples containing conditions and corresponding values.\n",
    "            target_var: The name of the new or existing column to store the result.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'A': [10, 15, 20]})\n",
    "        >>> cases = [('A > 15', 'High'), ('A <= 15', 'Low')]\n",
    "        >>> pi = piplyr(df).case_when(cases, 'Category')    \n",
    "        \"\"\"\n",
    "        self.df[target_var] = np.nan\n",
    "        for condition, value in cases:\n",
    "            self.df.loc[self.df.eval(condition), target_var] = value\n",
    "        return self\n",
    "\n",
    "    def join(self, other_df, by, join_type='inner'):\n",
    "        \"\"\"\n",
    "        Joins the current DataFrame with another DataFrame.\n",
    "\n",
    "        Args:\n",
    "            other_df: The DataFrame to join with.\n",
    "            by: The column name(s) to join on.\n",
    "            join_type: Type of join to perform ('inner', 'left', 'right', 'outer').\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        Example:    \n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6],'F':['a','b','c']})\n",
    "            >>> df2 = pd.DataFrame({'C': [10, 20], 'D': [40, 50],'F':['b','c']})\n",
    "            >>> piplyr(df).join(df2,'F','outer')\n",
    "        \"\"\"\n",
    "        if join_type not in ['inner', 'left', 'right', 'outer']:\n",
    "            raise ValueError(\"join_type must be one of 'inner', 'left', 'right', 'outer'\")\n",
    "        self.df = self.df.merge(other_df, on=by, how=join_type)\n",
    "        return self\n",
    "\n",
    "    def count_na(self):\n",
    "        \"\"\"\n",
    "        Counts the number of NA values in each column of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: A Series with the count of NA values for each column.\n",
    "            \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, np.nan]})\n",
    "        >>> na_count = piplyr(df).count_na()    \n",
    "        \"\"\"\n",
    "        return self.df.isna().sum()\n",
    "\n",
    "    # ... [Other existing methods] ...\n",
    "\n",
    "    def distinct(self, columns=None):\n",
    "        \"\"\"\n",
    "        Removes duplicate rows in the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            columns: The columns to consider for identifying duplicates. \n",
    "                     If None, all columns are considered.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'A': [1, 1, 2], 'B': [3, 3, 3]})\n",
    "        >>> pi = piplyr(df).distinct()\n",
    "        \"\"\"\n",
    "        self.df = self.df.drop_duplicates(subset=columns)\n",
    "        return self\n",
    "\n",
    "    def skim(self):\n",
    "        \"\"\"\n",
    "        Provides a summary of the DataFrame's statistics.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing summary statistics for each column.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "        >>> summary = piplyr(df).skim()\n",
    "        \"\"\"\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        stats = {\n",
    "            'Types': self.df.dtypes,\n",
    "            'Missing Values': self.df.isna().sum(),\n",
    "            'Unique Values': self.df.nunique(),\n",
    "            'Min': self.df.select_dtypes(include=[np.number]).min(),\n",
    "            'Max': self.df.select_dtypes(include=[np.number]).max(),\n",
    "            'Mean': self.df.select_dtypes(include=[np.number]).mean(),\n",
    "            'Std': self.df.select_dtypes(include=[np.number]).std(),\n",
    "            '25%': self.df.select_dtypes(include=[np.number]).quantile(0.25),\n",
    "            '50%': self.df.select_dtypes(include=[np.number]).quantile(0.50),\n",
    "            '75%': self.df.select_dtypes(include=[np.number]).quantile(0.75)\n",
    "        }\n",
    "\n",
    "        # Convert stats dict to DataFrame\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "\n",
    "        # Fill non-applicable numeric stats with NaN for non-numeric columns\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype not in [np.number]:\n",
    "                stats_df.loc[['Min', 'Max', 'Mean', 'Std', '25%', '50%', '75%'], col] = np.nan\n",
    "\n",
    "        return stats_df\n",
    "    \n",
    "\n",
    "    def pivot_longer(self, cols, id_vars=None, var_name='variable', value_name='value'):\n",
    "        \"\"\"\n",
    "        Transforms the DataFrame from a wide format to a long format.\n",
    "\n",
    "        Args:\n",
    "            cols: Columns to unpivot.\n",
    "            id_vars: Columns to leave unchanged (identifier variables).\n",
    "            var_name: Name of the new column that will contain the variable names.\n",
    "            value_name: Name of the new column that will contain the values.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Name': ['A', 'B'], 'Val1': [1, 2], 'Val2': [3, 4]})\n",
    "        >>> pi = piplyr(df).pivot_longer(cols=['Val1', 'Val2'], id_vars='Name')    \n",
    "        \"\"\"\n",
    "        self.df = pd.melt(self.df, id_vars=id_vars, value_vars=cols, var_name=var_name, value_name=value_name)\n",
    "        return self\n",
    "\n",
    "    def pivot_wider(self, index, columns, values):\n",
    "        \"\"\"\n",
    "        Transforms the DataFrame from a long format to a wide format.\n",
    "\n",
    "        Args:\n",
    "            index: Column(s) to use as index (identifier variables).\n",
    "            columns: Column whose unique values will become new columns in the wide format.\n",
    "            values: Column(s) that will be spread across the new columns.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Name': ['A', 'A', 'B', 'B'], 'Variable': ['Val1', 'Val2', 'Val1', 'Val2'], 'Value': [1, 2, 3, 4]})\n",
    "        >>> pi = piplyr(df).pivot_wider(index='Name', columns='Variable', values='Value')    \n",
    "        \"\"\"\n",
    "        self.df = self.df.pivot(index=index, columns=columns, values=values)\n",
    "        return self\n",
    "\n",
    "    def clean_names(self):\n",
    "        \"\"\"\n",
    "        Cleans and standardizes column names by converting them to lowercase and replacing \n",
    "        non-alphanumeric characters with underscores.\n",
    "\n",
    "        Returns:\n",
    "            self: The modified piplyr object.\n",
    "            \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'First Name': [1, 2, 3], 'Last-Name': [4, 5, 6]})\n",
    "        >>> pi = piplyr(df).clean_names()    \n",
    "        \"\"\"\n",
    "        self.df.columns = [re.sub('[^0-9a-zA-Z]+', '_', col).lower() for col in self.df.columns]\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def separate(self, col, into, sep=None, remove=False, extra='warn'):\n",
    "        \"\"\"\n",
    "        Separates a column into multiple columns based on a separator.\n",
    "\n",
    "        Args:\n",
    "            col: Column name to be separated.\n",
    "            into: List of new column names after separation.\n",
    "            sep: Separator to split the column (default: split on whitespace).\n",
    "            remove: Flag to remove the original column (default: False).\n",
    "            extra: Specifies behavior if there are extra splits. Options are 'drop', 'merge', and 'warn'.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Name': ['John Doe', 'Jane Smith']})\n",
    "        >>> pi = piplyr(df).separate('Name', into=['FirstName', 'LastName'], sep=' ')\n",
    "        \"\"\"\n",
    "        split_cols = self.df[col].str.split(sep, expand=True)\n",
    "        num_cols = len(into)\n",
    "\n",
    "        if split_cols.shape[1] > num_cols:\n",
    "            if extra == 'drop':\n",
    "                split_cols = split_cols.iloc[:, :num_cols]\n",
    "            elif extra == 'merge':\n",
    "                split_cols.iloc[:, num_cols-1] = split_cols.iloc[:, num_cols-1:].apply(lambda x: sep.join(x.dropna().astype(str)), axis=1)\n",
    "                split_cols = split_cols.iloc[:, :num_cols]\n",
    "            elif extra == 'warn':\n",
    "                warnings.warn(\"Number of splits exceeds the length of 'into'; extra splits are being dropped.\")\n",
    "\n",
    "        self.df[into] = split_cols\n",
    "        if remove:\n",
    "            self.df = self.df.drop(columns=[col])\n",
    "        return self\n",
    "\n",
    "    def str_pad(self, column, width, side='left', pad=\" \"):\n",
    "        \"\"\"\n",
    "        Pads strings in a DataFrame column to a specified width.\n",
    "\n",
    "        Args:\n",
    "            column: The column to pad.\n",
    "            width: The width to pad the strings to.\n",
    "            side: The side to pad on ('left' or 'right').\n",
    "            pad: The character used for padding (default: space).\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Name': ['John', 'Jane']})\n",
    "        >>> pi = piplyr(df).str_pad('Name', 10, side='right', pad='_')\n",
    "        \"\"\"\n",
    "        if side not in ['left', 'right']:\n",
    "            raise ValueError(\"Side must be either 'left' or 'right'\")\n",
    "\n",
    "        if side == 'left':\n",
    "            self.df[column] = self.df[column].astype(str).str.pad(width, side='left', fillchar=pad)\n",
    "        else:  # side == 'right'\n",
    "            self.df[column] = self.df[column].astype(str).str.pad(width, side='right', fillchar=pad)\n",
    "        return self\n",
    "\n",
    "    def str_replace(self, pattern, replacement):\n",
    "        \"\"\"\n",
    "        Replaces a pattern in strings with a replacement string.\n",
    "\n",
    "        Args:\n",
    "            pattern: The regex pattern to replace.\n",
    "            replacement: The replacement string.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Text': ['foo123', 'bar456', 'baz789']})\n",
    "        >>> pi = piplyr(df).str_sub('\\\\d+', 'XYZ')\n",
    "        \"\"\"\n",
    "        self.df = self.df.applymap(lambda x: re.sub(pattern, replacement, str(x)) if isinstance(x, str) else x)\n",
    "        return self\n",
    "\n",
    "    def str_extract(self, pattern, col=None):\n",
    "        \"\"\"\n",
    "        Extracts a pattern from a string column.\n",
    "\n",
    "        Args:\n",
    "            pattern: The regex pattern to extract.\n",
    "            col: The column to apply extraction. If None, applies to all string columns.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "        \n",
    "        Examples:\n",
    "        >>> df = pd.DataFrame({'Text': ['apple123', 'banana456', 'cherry789']})\n",
    "        >>> pi = piplyr(df).str_extract('(\\\\d+)', 'Text')\n",
    "        \"\"\"\n",
    "        if col:\n",
    "            self.df[col + '_extracted'] = self.df[col].str.extract(pattern)\n",
    "        else:\n",
    "            for c in self.df.columns:\n",
    "                if self.df[c].dtype == object:\n",
    "                    self.df[c + '_extracted'] = self.df[c].str.extract(pattern)\n",
    "        return self\n",
    "\n",
    "    def str_detect(self, col, pattern):\n",
    "        \"\"\"\n",
    "        Detects if a pattern exists in a string column.\n",
    "\n",
    "        Args:\n",
    "            col: The column to check for the pattern.\n",
    "            pattern: The regex pattern to detect.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with a new column indicating detection.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['foo', 'bar', 'baz']})\n",
    "            >>> pi = piplyr(df).str_detect('A','foo')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col + '_detected'] = self.df[col].str.contains(pattern, na=False)\n",
    "        return self\n",
    "    \n",
    "    def str_len(self, col):\n",
    "        \"\"\"\n",
    "        Calculates the length of strings in a specified DataFrame column.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to calculate string lengths for.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with a new column appended indicating string lengths.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['foo', 'bar', 'baz']})\n",
    "            >>> pi = piplyr(df).str_len('A')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col + '_len'] = self.df[col].str.len()\n",
    "        return self\n",
    "\n",
    "    def str_lower(self, col):\n",
    "        \"\"\"\n",
    "        Converts strings in the specified column to lowercase.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to convert strings to lowercase.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the specified column converted to lowercase.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['FOO', 'Bar', 'BAZ']})\n",
    "            >>> pi = piplyr(df).str_lower('A')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col] = self.df[col].str.lower()\n",
    "        return self\n",
    "\n",
    "    def str_upper(self, col):\n",
    "        \"\"\"\n",
    "        Converts strings in the specified column to uppercase.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to convert strings to uppercase.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the specified column converted to uppercase.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['foo', 'bar', 'baz']})\n",
    "            >>> pi = piplyr(df).str_upper('A')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col] = self.df[col].str.upper()\n",
    "        return self\n",
    "\n",
    "    def str_startswith(self, col, prefix):\n",
    "        \"\"\"\n",
    "        Checks if strings in a specified column start with a given prefix.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to check.\n",
    "            prefix (str): The prefix to check for.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with a new column appended indicating if strings start with the prefix.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['apple', 'banana', 'cherry']})\n",
    "            >>> pi = piplyr(df).str_startswith('A', 'a')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col + '_startswith'] = self.df[col].str.startswith(prefix)\n",
    "        return self\n",
    "\n",
    "    def str_endswith(self, col, suffix):\n",
    "        \"\"\"\n",
    "        Checks if strings in a specified column end with a given suffix.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to check.\n",
    "            suffix (str): The suffix to check for.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with a new column appended indicating if strings end with the suffix.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['apple', 'banana', 'cherry']})\n",
    "            >>> pi = piplyr(df).str_endswith('A', 'e')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col + '_endswith'] = self.df[col].str.endswith(suffix)\n",
    "        return self\n",
    "\n",
    "    def str_contains(self, col, pattern):\n",
    "        \"\"\"\n",
    "        Checks if strings in a specified column contain a given pattern.\n",
    "\n",
    "        Args:\n",
    "            col (str): The column to check.\n",
    "            pattern (str): The pattern to check for.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with a new column appended indicating if strings contain the pattern.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'A': ['apple', 'banana', 'cherry']})\n",
    "            >>> pi = piplyr(df).str_contains('A', 'an')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[col + '_contains'] = self.df[col].str.contains(pattern)\n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def fct_lump(self, column, n=10, other_level='Other'):\n",
    "        \"\"\"\n",
    "        Lumps less frequent levels of a categorical column into an 'Other' category.\n",
    "\n",
    "        Args:\n",
    "            column: The name of the categorical column.\n",
    "            n: The minimum count to not be lumped into 'Other'.\n",
    "            other_level: The name for the lumped category (default: 'Other').\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Category': ['A', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D', 'D']})\n",
    "            >>> pi = piplyr(df).fct_lump('Category', n=3)\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        value_counts = self.df[column].value_counts()\n",
    "        self.df[column] = np.where(self.df[column].isin(value_counts.index[value_counts >= n]), self.df[column], other_level)\n",
    "        return self\n",
    "\n",
    "    def fct_infreq(self, column, frac=0.01, other_level='Other'):\n",
    "        \"\"\"\n",
    "        Lumps infrequent levels of a categorical column based on a fraction of total occurrences.\n",
    "\n",
    "        Args:\n",
    "            column: The name of the categorical column.\n",
    "            frac: Fraction of total occurrences to be considered infrequent.\n",
    "            other_level: The name for the lumped category (default: 'Other').\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Category': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']})\n",
    "            >>> pi = piplyr(df).fct_infreq('Category', frac=0.1)\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        value_counts = self.df[column].value_counts(normalize=True)\n",
    "        self.df[column] = np.where(self.df[column].isin(value_counts.index[value_counts >= frac]), self.df[column], other_level)\n",
    "        return self\n",
    "\n",
    "    def fct_relevel(self, column, ref_level, after=True):\n",
    "        \"\"\"\n",
    "        Reorders levels of a categorical column, moving a specified level to the first or last.\n",
    "\n",
    "        Args:\n",
    "            column: The name of the categorical column.\n",
    "            ref_level: The reference level to move.\n",
    "            after: Whether to move the reference level after the other levels.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Category': ['B', 'A', 'C']})\n",
    "            >>> pi = piplyr(df).fct_relevel('Category', 'B', after=False)\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        self.df[column] = pd.Categorical(self.df[column], categories=self.df[column].unique(), ordered=True)\n",
    "        if ref_level not in self.df[column].cat.categories:\n",
    "            raise ValueError(f\"Reference level '{ref_level}' not found in column '{column}'\")\n",
    "        if after:\n",
    "            new_order = [cat for cat in self.df[column].cat.categories if cat != ref_level] + [ref_level]\n",
    "        else:\n",
    "            new_order = [ref_level] + [cat for cat in self.df[column].cat.categories if cat != ref_level]\n",
    "        self.df[column] = self.df[column].cat.reorder_categories(new_order)\n",
    "        return self\n",
    "\n",
    "    def fct_recode(self, column, recode_dict, drop_unused=False):\n",
    "        \"\"\"\n",
    "        Recodes levels of a categorical column.\n",
    "\n",
    "        Args:\n",
    "            column: The name of the categorical column.\n",
    "            recode_dict: Dictionary mapping old levels to new levels.\n",
    "            drop_unused: Whether to drop unused categories after recoding.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Category': ['A', 'B', 'C']})\n",
    "            >>> pi = piplyr(df).fct_recode('Category', {'A': 'X', 'B': 'Y'})\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        if not all(level in self.df[column].cat.categories for level in recode_dict.keys()):\n",
    "            raise ValueError(\"One or more levels to recode not found in column categories\")\n",
    "        self.df[column] = self.df[column].cat.rename_categories(recode_dict)\n",
    "        if drop_unused:\n",
    "            self.df[column] = self.df[column].cat.remove_unused_categories()\n",
    "        return self\n",
    "\n",
    "    def fct_reorder(self, column, order_by, ascending=True):\n",
    "        \"\"\"\n",
    "        Reorders the levels of a categorical column based on another column.\n",
    "\n",
    "        Args:\n",
    "            column: The name of the categorical column.\n",
    "            order_by: The column by which to order the categories.\n",
    "            ascending: Whether to sort the categories in ascending order (default: True).\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the DataFrame modified.\n",
    "\n",
    "        Examples:\n",
    "            >>> df = pd.DataFrame({'Category': ['A', 'B', 'C'], 'Values': [3, 1, 2]})\n",
    "            >>> pi = piplyr(df).fct_reorder('Category', 'Values')\n",
    "            >>> print(pi.to_df)\n",
    "        \"\"\"\n",
    "        ordering = self.df[order_by].argsort()\n",
    "        if not ascending:\n",
    "            ordering = ordering[::-1]\n",
    "        self.df[column] = pd.Categorical(self.df[column], categories=np.array(self.df[column])[ordering], ordered=True)\n",
    "        return self\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def __call__(self, df):\n",
    "        \"\"\"\n",
    "        Allows the piplyr object to be called with a new DataFrame, replacing the current one.\n",
    "\n",
    "        Args:\n",
    "            df: A new pandas DataFrame to replace the current one.\n",
    "\n",
    "        Returns:\n",
    "            self: The piplyr object with the new DataFrame.\n",
    "        \"\"\"\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "        self.df = df\n",
    "        self.grouped = None\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            str: A string representation of the DataFrame.\n",
    "        \"\"\"\n",
    "        return self.df.__repr__()\n",
    "\n",
    "    @property\n",
    "    def to_df(self):\n",
    "        \"\"\"\n",
    "        Converts the piplyr object's DataFrame to a standard pandas DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame contained within the piplyr object.\n",
    "            Examples:\n",
    "            >>> df = pd.DataFrame({'A': [1, 2, 3]})\n",
    "            >>> pi = piplyr(df)\n",
    "            >>> print(pi.to_df())\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'A': [10, 6, 3], 'B': [4, 5, 6],'F':['a','b','a']})\n",
    "df2 = pd.DataFrame({'C': [10, 20], 'D': [40, 50],'F':['b','c']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   F   A\n",
       "0  a  13\n",
       "1  b   2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piplyr(df).c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shh/Google_Drive/piplyr/piplyr/piplyr.py:435: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'High' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.df.loc[self.df.eval(condition), target_var] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    A  B  F   Cat\n",
       "0  10  4  a  High\n",
       "1   6  5  b   six\n",
       "2   3  6  a   Low"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [10, 6, 3], 'B': [4, 5, 6],'F':['a','b','a']})\n",
    "cases = [('A > 9', 'High'), \n",
    "         ('A <= 5', 'Low'),\n",
    "         ('A == 6', 'six')\n",
    "     \n",
    "         ]\n",
    "piplyr(df).case_when(cases,'Cat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shh/Google_Drive/piplyr/piplyr/piplyr.py:435: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'High' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  self.df.loc[self.df.eval(condition), target_var] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    A  B  F   Cat\n",
       "0  10  4  a  High\n",
       "1   7  5  b   NaN\n",
       "2   3  6  a   Low"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [10, 7, 3], 'B': [4, 5, 6], 'F': ['a', 'b', 'a']})\n",
    "cases = [('A > 7', 'High'), ('A <= 4', 'Low')]\n",
    "piplyr(df).case_when(cases, 'Cat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
